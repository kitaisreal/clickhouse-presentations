<!DOCTYPE html>
<html lang="en">
<head>
    <title>YDB ARM Performance Optimizations</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="shower/themes/yandex/styles/screen-16x9.css">

    <style type="text/css">
        code { display: block; white-space: pre; background-color: #EEE; }
        p.cloud { text-align: center; line-height: 1.5; }
        p.cloud span { font-size: 13pt; color: gray; padding: 0 20px 0 20px; white-space: nowrap; }
   </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>YDB ARM Performance Optimizations</h1>
    </header>

    <section class="slide" id="cover" style="background: #FFF url('pictures/front.png') no-repeat; background-size: 100%;">
    </section>

    <section class="slide">
        <h2>About me</h2>

        <p>Maksim, developer of YDB.</p>
        <a href="https://maksimkita.com/">https://maksimkita.com/</a></p>
    </section>

    <section class="slide">
        <h2>Plan</h2>

        <p>1. ARM optimization basics.</p>
        <p>2. Benchmarks.</p>
        <p>3. ClickBench.</p>
        <p>4. YSCB.</p>
        <p>5. TPC-C.</p>
    </section>

    <section class="slide">
        <h1 style="margin-top: 150px;">ARM optimization basics</h1>
    </section>

    <section class="slide">
        <h2>ARM optimization problems</h2>

        <p>Main infrastructure problems:</p>

        <p>1. Low-level libraries do not always have ARM support.</p>
        <p>2. Low-level libraries are not optimized for ARM. Examples: compression/decompression libraries (lz4, zstd), hashes.</p>
        <p>3. Tools are not optimized (objdump, perf).</p>
        <p>4. Compilers generate less efficient code (gcc, clang). ARM backends have less platform specific optimizations.</p>
    </section>

    <section class="slide">
        <h2>ARM optimization problems</h2>

        <p>Main implementation problems:</p>

        <p>1. Different costs (virtual function call, atomics, read/write unaligned memory, etc.).</p>
        <p>2. Neon is not SSE4.2, AVX2, AVX512. Example: No <b>pmovmskb</b> instruction. Libraries that convert Neon to X86-64 SIMD are
            not efficient.</p>
        <p>3. A lot of platform dependend code (X86-64).</p>

        <p><a href="https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/graviton_perfrunbook.md">https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/graviton_perfrunbook.md</a></p>
    </section>

    <section class="slide">
        <h2>ARM atomics</h2>

        <p>ARM is weakly ordered, similar to POWER and other modern architectures. While
            x86 is a variant of total-store-ordering (TSO).</p>
        <p>Code that relies on TSO may lack barriers to properly order memory references.</p>
        <p>ARMv8 based systems are <a href="https://www.cl.cam.ac.uk/~pes20/armv8-mca/armv8-mca-draft.pdf">
            weakly ordered multi-copy-atomic</a>.</p>
    </section>

    <section class="slide">
        <h2>ARM atomics</h2>

        <p>LSE (Large System Extensions).</p>
        <p>Enabled with <b>-moutline-atomics</b> compile flag to detect and use in runtime. Introduces run-time dispatch overhead.</p>
        <p>Can be enabled without run-time dispatch with <b>-march=armv8.2-a</b>.</p>
        <p>Supported by Graviton 2, Kunpeng 920-4826 and all recent ARM CPUs.</p>

        <p><a href="https://learn.arm.com/learning-paths/servers-and-cloud-computing/lse/intro/">https://learn.arm.com/learning-paths/servers-and-cloud-computing/lse/intro/</a></p>
    </section>

    <section class="slide">
        <h2>ARM atomics</h2>

        <p>LSE introduces a set of atomic instructions:</p>

        <p>1. Compare and Swap instructions: CAS and CASP</p>
        <p>2. Atomic memory operation instructions: LD&lt;op&gt; and ST&lt;op&gt;, where &lt;op&gt; is one of ADD, CLR, EOR, SET, SMAX, SMIN, UMAX, and UMIN</p>
        <p>3. Swap instruction: SWP</p>
    </section>

    <section class="slide">
        <h2>ARM atomics</h2>

        <p>In architecture versions prior to LSE, read-modify-write sequences use load exclusive and store exclusive instructions.</p>
        <p>Incrementing a shared variable uses a sequence such as:</p>
        <p>1. LDXR to read current count (load exclusive).</p>
        <p>2. ADD to add one to the shared variable.</p>
        <p>3. STXR to attempt to store to memory (store exclusive).</p>
        <p>4. CMP to check if the operation succeeded.</p>
    </section>

    <section class="slide">
        <h2>ARM atomics</h2>

        <code style="font-size: 14pt;">bool simpleCAS(std::atomic&lt;int64_t&gt; value,
    int64_t old_value,
    int64_t new_value)
{
    return value.compare_exchange_strong(old_value, new_value);
}
    </code>
    </section>

    <section class="slide">
        <h2>ARM without LSE</h2>

        <p>Loop inside CAS:</p>
        <p></p>
        <code style="font-size: 14pt;">0000000000400690 &lt;_Z9simpleCASSt6atomicIlEll&gt;:
 <b>400690:	c85ffc03 	ldaxr	x3, [x0]</b>
 <b>400694:	eb01007f 	cmp	x3, x1</b>
 <b>400698:	54000061 	b.ne	4006a4</b>
 <b>40069c:	c804fc02 	stlxr	w4, x2, [x0]</b>
 <b>4006a0:	35ffff84 	cbnz	w4, 400690</b>
 4006a4:	1a9f17e0 	cset	w0, eq
 4006a8:	d65f03c0 	ret
 4006ac:	d503201f 	nop
    </code>
    </section>

    <section class="slide">
        <h2>ARM with LSE</h2>

        <p>No loop inside CAS:</p>
        <p></p>
        <code style="font-size: 14pt;">0000000000400690 &lt;_Z9simpleCASSt6atomicIlEll&gt;:
 <b>400690:	aa0103e3 	mov	x3, x1</b>
 <b>400694:	c8e3fc02 	casal	x3, x2, [x0]</b>
 <b>400698:	eb01007f 	cmp	x3, x1</b>
 40069c:	1a9f17e0 	cset	w0, eq
 4006a0:	d65f03c0 	ret
        </code>
    </section>

    <section class="slide">
        <h2>ARM spinlock benchmark</h2>

        <code style="font-size: 10pt;">class SpinLock
{
public:
    void lock()
    {
        while (true)
        {
            if (!lock_.exchange(true, std::memory_order_acq_rel))
                break;

            while (lock_.load(std::memory_order_relaxed))
                pauseYield();
        }
    }

    void unlock()
    {
        lock_.store(false, std::memory_order_release);
    }
private:
    std::atomic&lt;bool&gt; lock_;
};
    </code>
    </section>

    <section class="slide">
        <h2>ARM spinlock lock without LSE</h2>

        <code style="font-size: 14pt;">0000000000400690 &lt;_ZN8SpinLock4lockEv&gt;:
  400690:	52800022 	mov	w2, #0x1
  400694:	d503201f 	nop
  <b>400698:	085ffc01 	ldaxrb	w1, [x0]</b>
  <b>40069c:	0803fc02 	stlxrb	w3, w2, [x0]</b>
  <b>4006a0:	35ffffc3 	cbnz	w3, 400698</b>
  4006a4:	72001c3f 	tst	w1, #0xff
  4006a8:	540000c0 	b.eq	4006c0
  4006ac:	39400001 	ldrb	w1, [x0]
  4006b0:	72001c3f 	tst	w1, #0xff
  4006b4:	54ffff20 	b.eq	400698
  4006b8:	d503203f 	yield
  4006bc:	17fffffc 	b	4006ac
  4006c0:	d65f03c0 	ret
  4006c4:	d503201f 	nop
  4006c8:	d503201f 	nop

00000000004006d0 &lt;_ZN8SpinLock6unlockEv&gt;:
  4006d0:	089ffc1f 	stlrb	wzr, [x0]
  4006d4:	d65f03c0 	ret
        </code>
        </section>

    <section class="slide">
        <h2>ARM spinlock lock with LSE</h2>

        <code style="font-size: 14pt;">0000000000400690 &lt;_ZN8SpinLock4lockEv&gt;:
  400690:	52800022 	mov	w2, #0x1
  400694:	d503201f 	nop
  <b>400698:	38e28001 	swpalb	w2, w1, [x0]</b>
  40069c:	72001c3f 	tst	w1, #0xff
  4006a0:	540000e0 	b.eq	4006bc
  4006a4:	d503201f 	nop
  4006a8:	39400001 	ldrb	w1, [x0]
  4006ac:	72001c3f 	tst	w1, #0xff
  4006b0:	54ffff40 	b.eq	400698
  4006b4:	d503203f 	yield
  4006b8:	17fffffc 	b	4006a8
  4006bc:	d65f03c0 	ret

00000000004006c0 &lt;_ZN8SpinLock6unlockEv&gt;:
  4006c0:	089ffc1f 	stlrb	wzr, [x0]
  4006c4:	d65f03c0 	ret
</code>
        </section>

    <section class="slide">
        <h2>ARM spinlock benchmark</h2>

        <p>Run simple benchmark to measure <b>lock</b>, <b>unlock</b> performance for 16 threads.</p>

        <p>Without LSE: <b>9250 ms</b>.</p>
        <p>With LSE: <b>3114 ms</b>.</p>
    </section>

    <section class="slide">
        <h2>ARM proper memory orders</h2>

        <p>Almost does not matter on X86-64. Matters a lot on ARM.</p>
        <p>1. sequential-consistency</p>
        <p>2. acquire/release</p>
        <p>3. relaxed</p>
    </section>

    <section class="slide">
        <h2>ARM proper memory orders</h2>

        <p>In old libraries can be a lot of suboptimal implementation of synchronization primitives, spinlocks, custom lock-free data structures, memory barriers.</p>
        <p>Probably contain a lot of bugs on ARM, because was tested only on X86-64.</p>
        <p>Very hard to maintain, modify.</p>
        <p>All new code need to use <b>std::atomic</b> and build synchronization primitives on top of it.</p>
    </section>

    <section class="slide">
        <h2>ARM cache line size</h2>

        <p>Platform dependend paddings:</p>

        <code style="font-size: 12pt;">alignas(64) std::atomic&lt;uint64_t&gt; state;
char padding[64 - sizeof(state)];</code>
        <p></p>
        <p>Can be replaced with:</p>
        <code style="font-size: 12pt;">alignas(hardware_destructive_interference_size) std::atomic&lt;uint64_t&gt; state;
char padding[hardware_destructive_interference_size - sizeof(state)];</code>
        <p></p>
        <p style="font-size: 14pt;"><a href="https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size">https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size</a></p>
    </section>

    <section class="slide">
        <h2>ARM SIMD</h2>

        <p>1. Autovectorization. Preferred option.</p>
        <p>2. Manual SIMD instructions using intrinsics or assembly.</p>

        <p>X86-64 intrinsics usage header examples:</p>
        <code style="font-size: 16pt;">#include &lt;immintrin.h&gt;
#include &lt;emmintrin.h&gt;</code>

        <p></p>

        <p>Special libraries can help with X86-64 intrinsics rewritting:</p>
        <p><a href="https://github.com/simd-everywhere/simde">https://githcom/simd-everywhere/simde</a></p>
        <p><a href="https://github.com/DLTcollab/sse2neon">https://github.com/DLTcollab/sse2neon</a></p>
    </section>

    <section class="slide">
        <h2>ARM libraries</h2>

        <p>A lot of platform dependend code (X86-64).</p>

        <code style="font-size: 14pt;">#if defined(__x86_64__)

#ifdef __SSE2__

#if defined(__AVX__) || defined(__AVX2__)

#ifdef __BMI__
</code>
    </section>

    <section class="slide">
        <h2>ARM libraries</h2>

        <p>Add special branches for ARM (AARCH64):</p>
        <code style="font-size: 14pt;">#if defined(__aarch64__)</code>

        <p></p>
        <p>For SIMD intrinsics:</p>
        <code style="font-size: 14pt;">#if defined(__ARM_NEON)
#include &lt;arm_neon.h&gt;
#endif</code>

    </section>

    <section class="slide">
        <h2>ARM CRC library</h2>

        <code style="font-size: 18pt;">SELECT COUNT(*) FROM hits;</code>
        <p></p>
        <p>Perf top output:</p>
        <code style="font-size: 10pt;">Samples: 1M of event 'cycles:P', 4000 Hz, Event count (approx.): 165205540299 lost: 0/0 drop: 0/588582
Overhead  Shared Object            Symbol
  <b>29,19%  ydbd                     [.] crcutil_interface::Implementation&lt;crcutil::GenericCrc></b>
   9,03%  ydbd                     [.] ChaCha::Encipher
   6,20%  ydbd                     [.] NActors::TExecutorThreadStats::Aggregate
   2,79%  [kernel]                 [k] __arch_copy_to_user
   2,66%  ydbd                     [.] t1ha1_le
   2,07%  [kernel]                 [k] finish_task_switch
   2,00%  [kernel]                 [k] __arch_copy_from_user
   1,75%  ydbd                     [.] NActors::TBasicExecutorPool::GoToSpin
   1,48%  ydbd                     [.] NKikimr::NTable::NPage::TDataPageRecord
   1,46%  ydbd                     [.] TTcpPacketOutTask::Finish
   1,23%  ydbd                     [.] XXH_INLINE_XXH3_64bits_update
   0,96%  [kernel]                 [k] try_to_wake_up
   0,68%  libc.so.6                [.] 0x0000000000098fc0
   0,65%  ydbd                     [.] NActors::TBasicExecutorPool::GetReadyActivation
   0,58%  libc.so.6                [.] 0x0000000000098fcc
   0,57%  libc.so.6                [.] 0x0000000000098fbc
   0,52%  libc.so.6                [.] 0x0000000000098fc4
        </code>
    </section>

    <section class="slide">
        <h2>ARM CRC library</h2>

        <img style="width: 100%;" src="pictures/crc32_flamegraph_before.png"/>
    </section>

    <section class="slide">
        <h2>ARM CRC library</h2>

        <p>Problem was invalid architecture dispatch inside CRC library.</p>
        <p>For ARM CRC library dispatched into the most inneficient implementation.</p>
    </section>

    <section class="slide">
        <h2>ARM CRC library after fix</h2>

        <p>Perf top output:</p>

        <code style="font-size: 10pt;">Samples: 801K of event 'cycles:P', 4000 Hz, Event count (approx.): 109659260334 lost: 0/0 drop: 0/569470
Overhead  Shared Object            Symbol
  11,40%  ydbd                 [.] ChaCha::Encipher
   8,15%  ydbd                 [.] NActors::TExecutorThreadStats::Aggregate
   <b>5,10%  ydbd                 [.] crcutil::GenericCrc</b>
   2,82%  [kernel]             [k] __arch_copy_to_user
   2,68%  ydbd                 [.] NKikimr::NTable::NPage::TDataPageRecord
   2,36%  ydbd                 [.] t1ha1_le
   2,26%  [kernel]             [k] finish_task_switch
   2,00%  ydbd                 [.] NActors::TBasicExecutorPool::GoToSpin
   1,75%  ydbd                 [.] TTcpPacketOutTask::Finish
   1,56%  ydbd                 [.] XXH_INLINE_XXH3_64bits_update
   1,39%  [kernel]             [k] __arch_copy_from_user
   1,28%  libc.so.6            [.] 0x0000000000098fc0
   1,24%  ydbd                 [.] NKikimr::NTable::TPartSimpleIt::Apply
   1,23%  ydbd                 [.] NKikimr::TPinnedPageRef::TPinnedPageRef
   1,13%  perf                 [.] rb_next
   1,03%  [kernel]             [k] try_to_wake_up
   0,98%  libc.so.6            [.] 0x0000000000098fbc
   0,98%  ydbd                 [.] NActors::TBasicExecutorPool::GetReadyActivation
    </code>
    </section>

    <section class="slide">
        <h2>ARM CRC library after fix</h2>

        <p>Around 20% reduce of CPU usage.</p>
        <p>For queries after fix there is 10% - 20% performance improvement:</p>
        <code style="font-size: 18pt;">SELECT COUNT(*) FROM hits;</code>
        <p></p>
        <p>Was: <b style="color: red;">3091</b> ms</p>
        <p>Now: <b style="color: green;">2575</b> ms</p>
    </section>

    <section class="slide">
        <h1 style="margin-top: 150px;">ARM benchmarks</h1>
    </section>

    <section class="slide">
        <h2>ARM Cluster</h2>

        <p>9 nodes</p>
        <p>CPU: 2 x Kunpeng 920-4826 (2 x 48 = 96 physical cores).</p>
        <p>RAM: 502GB.</p>
        <p>Disk: SSD SAMSUNG MZ7LH960 (Sequential write around 500 MB/s, read around 500 MB/s).</p>
    </section>

    <section class="slide">
        <h2>X86-64 Cluster</h2>

        <p>9 nodes</p>
        <p>CPU: 2 x Intel(R) Xeon(R) Gold 6126 (2 x 12 = 24 physical cores, 24 * 2 = 48 virtual cores with hyper-threading).</p>
        <p>RAM: 375GB.</p>
        <p>Disk: SSD SDLF1CRM016T-1HH.</p>
    </section>

    <section class="slide">
        <h2>Benchmarks</h2>

        <p>Benchmarks:</p>
        <p>1. ClickBench.</p>
        <p>2. YCSB.</p>
        <p>3. TPC-C.</p>
    </section>

    <section class="slide">
        <h1 style="margin-top: 150px;">ClickBench</h1>
    </section>

    <section class="slide">
        <h2>ClickBench</h2>

        <p>ClickBench <a href="https://github.com/ClickHouse/ClickBench">https://github.com/ClickHouse/ClickBench</a></p></p>
        <p>Data is based on obfuscated data from Yandex.Metrica production.</p>
        <p>Dataset contains 100m rows, 70GB uncompressed data.</p>
        <p>Queries mostly analytical, but some contain unindexed key lookups:</p>
        <code style="font-size: 16pt;">SELECT UserID FROM hits WHERE UserID = 435090932899640449;</code>
        <p></p>
        <p>Main goal is to utilize and stress test system under pressure, to find some hotspots that can be optimized.</p>
    </section>

    <section class="slide">
        <h2>ARM ClickBench upload</h2>

        <p>ARM data single machine upload time:</p>

        <code style="font-size: 18pt;">YDB row storage - 911 seconds (15 min)
Postgres - 1450 seconds (24 min)</code>
        <p></p>
    </section>

    <section class="slide">
        <h2>X86-64 ClickBench upload</h2>

        <p>X86-64 data single machine upload time:</p>
        <code style="font-size: 18pt;">YDB row storage - 1298 seconds (22 min)
Postgres - 1730 seconds (30 min)</code>
    </section>

    <section class="slide">
        <h2>ClickBench configuration</h2>

        <p>YDB configuration: 1 storage node, 4 dynamic nodes (standard configuration for large servers). All nodes are on single physical machine.</p>
        <p>PostgreSQL configuration: optimized version for ClickBench
            <a href="https://github.com/ClickHouse/ClickBench/tree/8d51fca14edb2013d3c7f8624517d4adf5af344d/postgresql-tuned">
                https://github.com/ClickHouse/ClickBench/tree/main/postgresql-tuned
            </a>
        (number of workers and buffers sizes increased to fully match machine capabilities).</p>
    </section>

    <section class="slide">
        <h2>ARM YDB/PostgreSQL ClickBench</h2>

        <img style="width: 85%;" src="pictures/aarch64_hits_full_postgres_ydb.png"/>
    </section>

    <section class="slide">
        <h2>X86-64 YDB/PostgreSQL ClickBench</h2>

        <img style="width: 85%;" src="pictures/x86_64_hits_full_postgres_ydb.png"/>
    </section>

    <section class="slide">
        <h2>YDB JIT</h2>

        <p>JIT can provide a lot of performance improvements for analytical workloads (2x - 29x performance improvement).</p>
        <p>Currently available only for X86-64.</p>

        <code style="font-size: 18pt;">table_service_config:
    <b>enable_async_computation_pattern_compilation</b>: true</code>
    </section>

    <section class="slide">
        <h2>YDB JIT ClickBench</h2>

        <img style="width: 85%;" src="pictures/x86_64_hits_full_jit.png"/>
    </section>

    <section class="slide">
        <h2>YDB JIT ClickBench</h2>

        <code style="font-size: 14pt;">SELECT SUM(ResolutionWidth), SUM(ResolutionWidth + 1),
    SUM(ResolutionWidth + 2), SUM(ResolutionWidth + 3),
    SUM(ResolutionWidth + 4), SUM(ResolutionWidth + 5),
    SUM(ResolutionWidth + 6), SUM(ResolutionWidth + 7),
    SUM(ResolutionWidth + 8), SUM(ResolutionWidth + 9),
    SUM(ResolutionWidth + 10), SUM(ResolutionWidth + 11),
    SUM(ResolutionWidth + 12), SUM(ResolutionWidth + 13),
    SUM(ResolutionWidth + 14), SUM(ResolutionWidth + 15),
    ...
    SUM(ResolutionWidth + 87), SUM(ResolutionWidth + 88),
    SUM(ResolutionWidth + 89) FROM hits;</code>

        <br>
        <p>Before (without JIT): 56.1 seconds.</p>
        <p>After (with JIT): 1.9 seconds.</p>
</code>
    </section>

    <section class="slide">
        <h2>YDB ARM/X86-64 ClickBench</h2>

        <img style="width: 85%;" src="pictures/arm_x86_64_hits_full.png"/>
    </section>

    <section class="slide">
        <h2>ClickBench</h2>

        <p>Overall ARM is faster in 2-2.5 times.</p>
    </section>

    <section class="slide">
        <h1 style="margin-top: 150px;">YCSB</h1>
    </section>

    <section class="slide">
        <h2>YCSB</h2>

        <p>Yahoo! Cloud Serving Benchmark.</p>
        <p>Several different key-value workloads.</p>
        <p>Each workload can be parameterized using record count, threads and target queries for each thread.</p>
        <p>Zipfian distribution.</p>

        <p><a href="https://github.com/brianfrankcooper/YCSB">https://github.com/brianfrankcooper/YCSB</a></p>
        <p><a href="https://courses.cs.duke.edu/fall13/compsci590.4/838-CloudPapers/ycsb.pdf">Benchmarking Cloud Serving Systems with YCSB</a></p>
        <p><a href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipfian distribution</a></p>
    </section>

    <section class="slide">
        <h2>YCSB workloads</h2>

        <p>Workload A: Update heavy workload (50/50 reads/writes).</p>
        <p>Workload B: Read mostly workload (95/5 reads/writes).</p>
        <p>Workload C: Read only.</p>
        <p>Workload D: Read latest (insert new record and read inserted).</p>
        <p>Workload E: Read ranges.</p>
        <p>Workload F: Read-modify-write (read record modify it and write).</p>
    </section>

    <section class="slide">
        <h2>YCSB</h2>

        <p>Datasets: 100M (100 GB), 300M (300 Gb).</p>
        <p>Workloads: A, B, C, D, E, F.</p>
        <p>Threads: 512, 1024, 2048, 4096, 8192.</p>
    </section>

    <section class="slide">
        <h2>YCSB single node upload time</h2>

        <p>ARM upload time 100m: 2569 seconds.</p>
        <p>X86-64 upload time 100m: 3725 seconds.</p>
        <p>ARM is 50% faster.</p>
    </section>

    <section class="slide">
        <h2>YCSB 100m single node</h2>

        <code style="font-size: 20pt;">ydb -p test_db_cluster scheme describe usertable
--stats --partition-stats --permissions</code>

        <p></p>

        <code style="font-size: 20pt;">Table stats:
Partitions count: 80
Approximate number of rows: 100000000
Approximate size of table: 106.14 Gb</code>
    </section>

    <section class="slide">
        <h2>YCSB 100m A single node</h2>

        <img style="width: 85%;" src="pictures/arm_x86_single_node_ycsb_a.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m C single node</h2>

        <img style="width: 85%;" src="pictures/arm_x86_single_node_ycsb_c.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m single node summary</h2>

        <img style="width: 85%;" src="pictures/arm_x86_single_node_ycsb_summary.png"/>
    </section>

    <section class="slide">
        <h2>YCSB cluster upload time</h2>

        <p>ARM upload time 300m: 4991 seconds.</p>
        <p>X86-64 upload time 300m: 6285 seconds.</p>
        <p>ARM is 25% faster.</p>
    </section>

    <section class="slide">
        <h2>YCSB 300m cluster</h2>

        <code style="font-size: 20pt;">ydb -p test_db_cluster scheme describe usertable
--stats --partition-stats --permissions</code>

        <p></p>

        <code style="font-size: 20pt;">Table stats:
Partitions count: 229
Approximate number of rows: 300000400
Approximate size of table: 318.61 Gb</code>
    </section>

    <section class="slide">
        <h2>YCSB 300m A cluster</h2>

        <img style="width: 85%;" src="pictures/arm_x86_cluster_ycsb_a.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m C cluster</h2>

        <img style="width: 85%;" src="pictures/arm_x86_cluster_ycsb_c.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m cluster summary</h2>

        <img style="width: 85%;" src="pictures/arm_x86_cluster_ycsb_summary.png"/>
    </section>

    <section class="slide">
        <h2>YCSB</h2>

        <p>Throughput increases with increase of data size because of partitioning.</p>
        <p>ARM is 10-30% faster.</p>
        <p>ARM configuration is much more sensitive.</p>
    </section>

    <section class="slide">
        <h1 style="margin-top: 150px;">TPC-C</h1>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <p>Industry standard benchmark for OLTP databases.</p>
        <p>Complex schema for wholesale supplier database.</p>
        <p>Can be parameterized only with warehouse count.</p>
        <p>Each transaction can access multiple table with complex access patterns.</p>
        <p><a href="https://www.tpc.org/tpc_documents_current_versions/pdf/tpc-c_v5.11.0.pdf">TPC-C standard</a></p>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <img style="width: 85%;" src="pictures/tpcc_schema.png"/>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <p>TPM-C - NewOrder transactions per second.</p>
        <p>Efficiency - TPM-C / Maximum possible TPM-C.</p>
        <p>Latency numbers for each transaction type.</p>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <p>ARM uploads data 2-3 times faster.</p>
        <p>No significant differences in TPM-C on X86-64 and ARM for 10000-15000 warehouses.</p>
    </section>

    <section class="slide">
        <h2>Next steps</h2>

        <p>Performance improvements:</p>

        <p>1. Improve performance of ActorSystem for low-latency KV benchmarks (YCSB, TPC-C).</p>
        <p>2. Enable JIT for ARM.</p>
        <p>3. ARM tune low-level libraries (ChaCha encryption, XXH3 hash, etc.).</p>
    </section>

    <section class="slide">
        <h2>Conclusion</h2>

        <p>Most problems with ARM optimizations are different cost-model in comparison with X86-64 (virtual functions, atomics).</p>
        <p>Some things work great on X86-64, will not work on ARM or will be slow.</p>
        <p>Low-level libraries need to be optimized.</p>
    </section>

    <section class="slide" id="back" style="background: #FFF url('pictures/back.png') no-repeat; background-size: 100%;">
    </section>

    <div class="progress"></div>
    <script src="shower/shower.min.js"></script>

    <!--Video plugin-->
    <link rel="stylesheet" href="shower/shower-video.css">
    <script src="shower/shower-video.js"></script>
    <!--/Video plugin-->
</body>
</html>
