<!DOCTYPE html>
<html lang="en">
<head>
    <title>YDB AARCH64 Performance Optimizations</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="shower/themes/yandex/styles/screen-16x9.css">

    <style type="text/css">
        code { display: block; white-space: pre; background-color: #EEE; }
        p.cloud { text-align: center; line-height: 1.5; }
        p.cloud span { font-size: 13pt; color: gray; padding: 0 20px 0 20px; white-space: nowrap; }
   </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>YDB AARCH64 Performance Optimizations</h1>
    </header>

    <section class="slide" id="cover">
        <h1 style="margin-top: 150px;">YDB AARCH64 Performance Optimizations</h1>
    </section>

    <section class="slide">
        <h2>AARCH64 optimization problems</h2>

        <p>Main infrastructure problems:</p>

        <p>1. Low-level libraries does not always have AARCH64 support.</p>
        <p>2. Low-level libraries are not optimized. Example: compression/decompression libraries (lz4, zstd), hashes, etc.</p>
        <p>3. Tools are not optimized (objdump, perf).</p>
        <p>4. Compilers generate less efficient code (gcc, clang). AARCH64 backends have less platform specific optimizations.</p>
    </section>

    <section class="slide">
        <h2>AARCH64 optimization problems</h2>

        <p>Main implementation problems:</p>

        <p>1. Different costs (virtual function call, atomics, read/write unaligned memory, etc.)</p>
        <p>2. Neon is not SSE4.2, AVX2, AVX512. Example: No <b>pmovmskb</b> instruction. Libraries that convert Neon to X86-64 SIMD are
            not efficient.</p>
        <p>3. A lot of platform dependend code (X86-64).</p>

        <a href="https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/graviton_perfrunbook.md">https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/graviton_perfrunbook.md</a></p>
    </section>

    <section class="slide">
        <h2>AARCH64 atomics</h2>

        <p>ARM is weakly ordered, similar to POWER and other modern architectures. While
            x86 is a variant of total-store-ordering (TSO).</p>
        <p>Code that relies on TSO may lack barriers to properly order memory references.</p>
        <p>Armv8 based systems are <a href="https://www.cl.cam.ac.uk/~pes20/armv8-mca/armv8-mca-draft.pdf">
            weakly ordered multi-copy-atomic</a>.</p>
    </section>

    <section class="slide">
        <h2>AARCH64 atomics</h2>

        <p>LSE (Large System Extensions).</p>
        <p>Enabled with <b>-moutline-atomics</b> compile flag to detect and use in runtime. Introduces run-time dispatch overhead.</p>
        <p>Can be enabled without run-time dispatch with <b>-march=armv8.2-a</b>.</p>
    </section>

    <section class="slide">
        <h2>AARCH64 LSE before</h2>

        <code style="font-size: 14pt;">bool simpleCAS(std::atomic&lt;int64_t&gt; value,
    int64_t old_value,
    int64_t new_value)
{
    return value.compare_exchange_strong(old_value, new_value);
}
    </code>
    </section>

    <section class="slide">
        <h2>AARCH64 without LSE</h2>

        <p>Loop inside CAS.</p>
        <p></p>
        <code style="font-size: 14pt;">0000000000400690 &lt;_Z9simpleCASSt6atomicIlEll&gt;:
 <b>400690</b>:	c85ffc03 	ldaxr	x3, [x0]
 400694:	eb01007f 	cmp	x3, x1
 400698:	54000061 	<b>b.ne	4006a4</b>
 40069c:	c804fc02 	stlxr	w4, x2, [x0]
 4006a0:	35ffff84 	<b>cbnz	w4, 400690</b>
 <b>4006a4</b>:	1a9f17e0 	cset	w0, eq
 4006a8:	d65f03c0 	ret
 4006ac:	d503201f 	nop
    </code>
    </section>

    <section class="slide">
        <h2>AARCH64 with LSE</h2>

        <p>No loop inside CAS.</p>
        <code style="font-size: 14pt;">0000000000400690 &lt;_Z9simpleCASSt6atomicIlEll&gt;:
 400690:	aa0103e3 	mov	x3, x1
 400694:	c8e3fc02 	casal	x3, x2, [x0]
 400698:	eb01007f 	cmp	x3, x1
 40069c:	1a9f17e0 	cset	w0, eq
 4006a0:	d65f03c0 	ret
        </code>
    </section>

    <section class="slide">
        <h2>AARCH64 spin lock benchmark</h2>

        <p>Slightly suboptimal implementation in case of high-contention:</p>

        <code style="font-size: 10pt;">class SpinLock
{
public:
    void lock() {
        while (true) {
            if (!lock_.exchange(true, std::memory_order_acq_rel)) {
                break;
            }

            pauseYield();
        }
    }

    void unlock() {
        lock_.store(false, std::memory_order_release);
    }

    private:
        std::atomic<bool> lock_;
};
    </code>
    </section>

    <section class="slide">
        <h2>AARCH64 spin lock benchmark</h2>

        <p>CPU Kunpeng 920-4826 (96 cores).</p>
        <p>Run simple benchmark to measure <b>lock</b>, <b>unlock</b> performance for 16 threads.</p>

        <p>Without LSE: <b>9250 ms</b>.</p>
        <p>With LSE: <b>3114 ms</b>.</p>
    </section>

    <section class="slide">
        <h2>AARCH64 proper memory orders</h2>

        <p>Almost does not matter on X86. Does matter on ARM.</p>
        <p>1. sequential-consistency</p>
        <p>2. acquire/release</p>
        <p>3. relaxed</p>

        <p>TODO: Link to C++ memory order</p>
    </section>

    <section class="slide">
        <h2>AARCH64 proper memory orders</h2>

        <p>In old libraries can be a lot of suboptimal implementation of synchronization primitives, spin locks, custom lock-free data structures, memory barriers.</p>
        <p>Probably contain a lot of bugs on ARM, because was tested only on X86.</p>
        <p>Very hard to maintain, modify.</p>
        <p>All new code need to use <b>std::atomic</b> and build synchronization primitives on top of it.</p>
    </section>

    <section class="slide">
        <h2>AARCH64 CRC32 library</h2>

        <code style="font-size: 18pt;">SELECT COUNT(*) FROM hits_5m;</code>
        <p></p>
        <p>Perf top output:</p>
        <code style="font-size: 10pt;">Samples: 1M of event 'cycles:P', 4000 Hz, Event count (approx.): 165205540299 lost: 0/0 drop: 0/588582
Overhead  Shared Object            Symbol
  <b>29,19%  ydbd                     [.] crcutil_interface::Implementation&lt;crcutil::GenericCrc></b>
   9,03%  ydbd                     [.] ChaCha::Encipher
   6,20%  ydbd                     [.] NActors::TExecutorThreadStats::Aggregate
   2,79%  [kernel]                 [k] __arch_copy_to_user
   2,66%  ydbd                     [.] t1ha1_le
   2,07%  [kernel]                 [k] finish_task_switch
   2,00%  [kernel]                 [k] __arch_copy_from_user
   1,75%  ydbd                     [.] NActors::TBasicExecutorPool::GoToSpin
   1,48%  ydbd                     [.] NKikimr::NTable::NPage::TDataPageRecord
   1,46%  ydbd                     [.] TTcpPacketOutTask::Finish
   1,23%  ydbd                     [.] XXH_INLINE_XXH3_64bits_update
   0,96%  [kernel]                 [k] try_to_wake_up
   0,68%  libc.so.6                [.] 0x0000000000098fc0
   0,65%  ydbd                     [.] NActors::TBasicExecutorPool::GetReadyActivation
   0,58%  libc.so.6                [.] 0x0000000000098fcc
   0,57%  libc.so.6                [.] 0x0000000000098fbc
   0,52%  libc.so.6                [.] 0x0000000000098fc4
        </code>
    </section>

    <section class="slide">
        <h2>AARCH64 CRC32 library</h2>

        <img style="width: 100%;" src="pictures/crc32_flamegraph_before.png"/>
    </section>

    <section class="slide">
        <h2>AARCH64 CRC library</h2>

        <p>Problem was invalid architecture dispatch inside CRC library.</p>
        <p>For AARCH64 CRC library dispatched into the most inneficient implementation.</p>
    </section>

    <section class="slide">
        <h2>AARCH64 CRC library after fix</h2>

        <p>Perf top output:</p>

        <code style="font-size: 10pt;">Samples: 801K of event 'cycles:P', 4000 Hz, Event count (approx.): 109659260334 lost: 0/0 drop: 0/569470
Overhead  Shared Object            Symbol
  11,40%  ydbd                 [.] ChaCha::Encipher
   8,15%  ydbd                 [.] NActors::TExecutorThreadStats::Aggregate
   <b>5,10%  ydbd                 [.] crcutil::GenericCrc</b>
   2,82%  [kernel]             [k] __arch_copy_to_user
   2,68%  ydbd                 [.] NKikimr::NTable::NPage::TDataPageRecord
   2,36%  ydbd                 [.] t1ha1_le
   2,26%  [kernel]             [k] finish_task_switch
   2,00%  ydbd                 [.] NActors::TBasicExecutorPool::GoToSpin
   1,75%  ydbd                 [.] TTcpPacketOutTask::Finish
   1,56%  ydbd                 [.] XXH_INLINE_XXH3_64bits_update
   1,39%  [kernel]             [k] __arch_copy_from_user
   1,28%  libc.so.6            [.] 0x0000000000098fc0
   1,24%  ydbd                 [.] NKikimr::NTable::TPartSimpleIt::Apply
   1,23%  ydbd                 [.] NKikimr::TPinnedPageRef::TPinnedPageRef
   1,13%  perf                 [.] rb_next
   1,03%  [kernel]             [k] try_to_wake_up
   0,98%  libc.so.6            [.] 0x0000000000098fbc
   0,98%  ydbd                 [.] NActors::TBasicExecutorPool::GetReadyActivation
    </code>
    </section>

    <section class="slide">
        <h2>AARCH64 CRC library after fix</h2>

        <img style="width: 100%; height: auto;" src="pictures/crc32_flamegraph_after.png"/>
    </section>

    <section class="slide">
        <h2>AARCH64 CRC library after fix</h2>

        <p>For queries after fix there is 10% - 20% performance improvement:</p>
        <p>Before:</p>
        <code style="font-size: 18pt;">SELECT COUNT(*) FROM hits_5m; median 12560.67</code>
        <p></p>
        <p>After:</p>
        <code style="font-size: 18pt;">SELECT COUNT(*) FROM hits_5m; median 11329.278</code>
    </section>

    <section class="slide">
        <h2>ARM Cluster</h2>

        <p>9 nodes</p>
        <p>CPU: Kunpeng 920-4826 (96 physical cores).</p>
        <p>RAM: 502GB.</p>
        <p>Disk: SSD SAMSUNG MZ7LH960 (Sequential write around 500 MB/s, read around 500 MB/s).</p>
    </section>

    <section class="slide">
        <h2>X86-64 Cluster</h2>

        <p>9 nodes</p>
        <p>CPU: Intel(R) Xeon(R) Gold 6126 (24 physical cores, 48 cores with hyper-threading).</p>
        <p>RAM: 375GB.</p>
        <p>Disk: SSD SDLF1CRM016T-1HH.</p>
    </section>

    <section class="slide">
        <h2>Benchmarks</h2>

        <p>Benchmarks:</p>
        <p>1. ClickBench.</p>
        <p>2. YCSB.</p>
        <p>3. TPC-C.</p>
    </section>

    <section class="slide">
        <h2>ClickBench</h2>

        <p>ClickBench <a href="https://github.com/ClickHouse/ClickBench">https://github.com/ClickHouse/ClickBench</a></p></p>
        <p>Data is based on obfuscated data from Yandex.Metrica production.</p>
        <p>Dataset contains 100m rows, 70GB uncompressed data.</p>
        <p>Queries mostly analytical, but some contain unindexed key lookups:</p>
        <code style="font-size: 16pt;">SELECT UserID FROM hits WHERE UserID = 435090932899640449;</code>
        <p></p>
        <p>Main goal is to utilize and stress test system under pressure, to find some hotspots that can be optimized.</p>
    </section>

    <section class="slide">
        <h2>AARCH64 ClickBench single machine upload</h2>

        <p>AARCH64 data upload time:</p>

        <code style="font-size: 18pt;">YDB row storage - 1740 seconds (29 min)
YDB row storage (reserve shards) - 911 seconds (15 min)
Postgres - 1450 seconds (24 min)</code>
        <p></p>
    </section>

    <section class="slide">
        <h2>X86-64 ClickBench single machine upload</h2>

        <p>X86-64 data upload time:</p>
        <code style="font-size: 18pt;">YDB row storage - 2756 seconds (45 min)
YDB row storage (reserve shards) - 1298 seconds (22 min)
Postgres - 1730 seconds (30 min)</code>
    </section>

    <section class="slide">
        <h2>ClickBench configuration</h2>

        <p>YDB configuration: 1 storage node, 4 dynamic nodes (standard configuration for large servers). All nodes are on single physical machine.</p>
        <p>PostgreSQL configuration: optimized version for ClickBench
            <a href="https://github.com/ClickHouse/ClickBench/tree/8d51fca14edb2013d3c7f8624517d4adf5af344d/postgresql-tuned">
                https://github.com/ClickHouse/ClickBench/tree/main/postgresql-tuned
            </a>
        (number of workers and buffers sizes increased to fully match machine capabilities).</p>
    </section>

    <section class="slide">
        <h2>AARCH64 ClickBench</h2>

        <img style="width: 85%;" src="pictures/aarch64_hits_full_postgres_ydb.png"/>
    </section>

    <section class="slide">
        <h2>X86-64 ClickBench</h2>

        <img style="width: 85%;" src="pictures/x86_64_hits_full_postgres_ydb.png"/>
    </section>

    <section class="slide">
        <h2>X86-64 JIT</h2>

        <p>JIT can provide a lot of performance improvements for analytical workloads (2x - 29x performance improvement).</p>
        <p>Currently available only for X86-64.</p>

        <code style="font-size: 18pt;">table_service_config:
    <b>enable_async_computation_pattern_compilation</b>: true</code>
    </section>

    <section class="slide">
        <h2>X86-64 JIT ClickBench</h2>

        <img style="width: 85%;" src="pictures/x86_64_hits_full_jit.png"/>
    </section>

    <section class="slide">
        <h2>X86-64 JIT ClickBench</h2>

        <code style="font-size: 14pt;">SELECT SUM(ResolutionWidth), SUM(ResolutionWidth + 1),
    SUM(ResolutionWidth + 2), SUM(ResolutionWidth + 3),
    SUM(ResolutionWidth + 4), SUM(ResolutionWidth + 5),
    SUM(ResolutionWidth + 6), SUM(ResolutionWidth + 7),
    SUM(ResolutionWidth + 8), SUM(ResolutionWidth + 9),
    SUM(ResolutionWidth + 10), SUM(ResolutionWidth + 11),
    SUM(ResolutionWidth + 12), SUM(ResolutionWidth + 13),
    SUM(ResolutionWidth + 14), SUM(ResolutionWidth + 15),
    ...
    SUM(ResolutionWidth + 87), SUM(ResolutionWidth + 88),
    SUM(ResolutionWidth + 89) FROM hits;</code>

        <br>
        <p>Before (without JIT): 56.1 seconds.</p>
        <p>After (with JIT): 1.9 seconds.</p>
</code>
    </section>

    <section class="slide">
        <h2>ClickBench on ARM X86 cluster</h2>

        <p>ARM upload time: 954 seconds.</p>
        <p>X86 upload time: 1440 seconds.</p>

        <p>ARM 50% faster.</p>
    </section>

    <section class="slide">
        <h2>ClickBench on cluster</h2>

        <img style="width: 85%;" src="pictures/arm_x86_cluster_hits_full.png"/>
    </section>

    <section class="slide">
        <h2>ClickBench on cluster</h2>

        <code style="font-size: 14pt;">SELECT SUM(ResolutionWidth), SUM(ResolutionWidth + 1),
    SUM(ResolutionWidth + 2), SUM(ResolutionWidth + 3),
    SUM(ResolutionWidth + 4), SUM(ResolutionWidth + 5),
    SUM(ResolutionWidth + 6), SUM(ResolutionWidth + 7),
    SUM(ResolutionWidth + 8), SUM(ResolutionWidth + 9),
    SUM(ResolutionWidth + 10), SUM(ResolutionWidth + 11),
    SUM(ResolutionWidth + 12), SUM(ResolutionWidth + 13),
    SUM(ResolutionWidth + 14), SUM(ResolutionWidth + 15),
    ...
    SUM(ResolutionWidth + 87), SUM(ResolutionWidth + 88),
    SUM(ResolutionWidth + 89) FROM hits;</code>

        <br>

        <p>ARM: 31 seconds.</p>
        <p>X86: 71 seconds.</p>
</code>
    </section>

    <section class="slide">
        <h2>ClickBench on cluster</h2>

        <p>Overall ARM is faster in 15-25%.</p>
    </section>

    <section class="slide">
        <h2>YCSB</h2>

        <p>Yahoo! Cloud Serving Benchmark.</p>
        <p>Several different key-value workloads.</p>
        <p>Each workload can be parameterized using record count, threads and target queries for each thread.</p>
        <p>Zipfian distribution.</p>

        <p><a href="https://github.com/brianfrankcooper/YCSB">https://github.com/brianfrankcooper/YCSB</a></p></p>
        <p><a href="https://courses.cs.duke.edu/fall13/compsci590.4/838-CloudPapers/ycsb.pdf">Benchmarking Cloud Serving Systems with YCSB</a></p></p>
        <p><a href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipfian distribution</a></p></p>
    </section>

    <section class="slide">
        <h2>YCSB workloads</h2>

        <p>Workload A: Update heavy workload (50/50 reads/writes).</p>
        <p>Workload B: Read mostly workload (95/5 reads/writes).</p>
        <p>Workload C: Read only.</p>
        <p>Workload D: Read latest (insert new record and read inserted).</p>
        <p>Workload E: Read ranges.</p>
        <p>Workload F: Read-modify-write (read record modify it and write).</p>
    </section>

    <section class="slide">
        <h2>YCSB</h2>

        <p>Datasets: 10M (10 GB), 100M (100 GB), 300M (300 Gb).</p>
        <p>Workloads: A, B, C, D, E, F.</p>
        <p>Threads: 1, 64, 128, 256, 512, 1024.</p>
    </section>

    <section class="slide">
        <h2>YCSB</h2>

        <p>ARM 10m, 100m, 300m upload time: 107, 1311, 3945 seconds.</p>
        <p>X86 10m, 100m, 300m upload time: 148, 1839, 6750 seconds.</p>

        <p>Almost linear scaling with increased amount of data.</p>
        <p>ARM is 30-50% faster.</p>
    </section>

    <section class="slide">
        <h2>YCSB 10m</h2>

        <code style="font-size: 20pt;">ydb -p test_db_cluster scheme describe usertable
--stats --partition-stats --permissions</code>

        <p></p>

        <code style="font-size: 16pt;">Table stats:
Partitions count: 50
Approximate number of rows: 10000000
Approximate size of table: 10.65 Gb</code>
    </section>

    <section class="slide">
        <h2>YCSB 10m A</h2>

        <img style="width: 85%;" src="pictures/ycsb_10m_workload_A.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 10m B</h2>

        <img style="width: 85%;" src="pictures/ycsb_10m_workload_B.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 10m C</h2>

        <img style="width: 85%;" src="pictures/ycsb_10m_workload_C.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 10m E</h2>

        <img style="width: 85%;" src="pictures/ycsb_10m_workload_E.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 10m F</h2>

        <img style="width: 85%;" src="pictures/ycsb_10m_workload_F.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 10m</h2>

        <img style="width: 85%;" src="pictures/ycsb_10m.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m</h2>

        <code style="font-size: 20pt;">ydb -p test_db_cluster scheme describe usertable
--stats --partition-stats --permissions</code>

        <p></p>

        <code style="font-size: 16pt;">Table stats:
Partitions count: 80
Approximate number of rows: 100000000
Approximate size of table: 106.14 Gb</code>
    </section>

    <section class="slide">
        <h2>YCSB 100m A</h2>

        <img style="width: 85%;" src="pictures/ycsb_100m_workload_A.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m B</h2>

        <img style="width: 85%;" src="pictures/ycsb_100m_workload_B.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m C</h2>

        <img style="width: 85%;" src="pictures/ycsb_100m_workload_C.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m E</h2>

        <img style="width: 85%;" src="pictures/ycsb_100m_workload_E.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m F</h2>

        <img style="width: 85%;" src="pictures/ycsb_100m_workload_F.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 100m</h2>

        <img style="width: 85%;" src="pictures/ycsb_100m.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m</h2>

        <code style="font-size: 20pt;">ydb -p test_db_cluster scheme describe usertable
--stats --partition-stats --permissions</code>

        <p></p>

        <code style="font-size: 16pt;">Table stats:
Partitions count: 229
Approximate number of rows: 300000400
Approximate size of table: 318.61 Gb</code>
    </section>

    <section class="slide">
        <h2>YCSB 300m A</h2>

        <img style="width: 85%;" src="pictures/ycsb_300m_workload_A.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m B</h2>

        <img style="width: 85%;" src="pictures/ycsb_300m_workload_B.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m C</h2>

        <img style="width: 85%;" src="pictures/ycsb_300m_workload_C.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m E</h2>

        <img style="width: 85%;" src="pictures/ycsb_300m_workload_E.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m F</h2>

        <img style="width: 85%;" src="pictures/ycsb_300m_workload_F.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m</h2>

        <img style="width: 85%;" src="pictures/ycsb_300m.png"/>
    </section>

    <section class="slide">
        <h2>YCSB 300m</h2>

        <p>Throughput increases with increase of data size because of partitioning.</p>
        <p>ARM does not have any scalability issues, only CPU underutilization.</p>
    </section>

    <section class="slide">
        <h2>YCSB ARM Workload A Flame Graph</h2>

        <img style="width: 100%;" src="pictures/ycsb_arm_100m_workload_a_framegraph.png"/>
    </section>

    <section class="slide">
        <h2>YCSB ARM Workload A Flame Graph</h2>

        <img style="width: 100%;" src="pictures/ycsb_arm_100m_workload_a_actor_system_flamegraph.png"/>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <p>Industry standard benchmark for OLTP databases.</p>
        <p>Complex schema for wholesale supplier database.</p>
        <p>Can be parameterized only with warehouse count.</p>
        <p>Each transaction can access multiple table with complex access patterns.</p>
        <p><a href="https://www.tpc.org/tpc_documents_current_versions/pdf/tpc-c_v5.11.0.pdf">TPC-C standard</a></p>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <img style="width: 85%;" src="pictures/tpcc_schema.png"/>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <p>TPM-C - NewOrder transactions per second.</p>
        <p>Efficiency - TPM-C / Maximum possible TPM-C.</p>
        <p>Latency numbers for each transaction type.</p>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <p>ARM 1000, 2500 warehouses upload time: 592, 1361 seconds.</p>
        <p>X86 1000, 2500 warehouses upload time: 1860, 2591 seconds.</p>
    </section>

    <section class="slide">
        <h2>TPC-C</h2>

        <p>ARM</p>
        <p>1000 warehouses TPM-C 12186.</p>
        <p>2500 warehouses TPM-C 24510.</p>

        <p>X86</p>
        <p>1000 warehouses TPM-C 12093.</p>
        <p>2500 warehouses TPM-C 23910.</p>

        <p>In all cases efficiency higher than 97%.</p>
    </section>

    <section class="slide">
        <h2>Next steps</h2>

        <p>Testing:</p>
        <p>1. Run bigger version of TPCC.</p>

        <p>Performance improvements:</p>

        <p>1. Improve performance for low-latency KV benchmarks (YCSB, TPCC)</p>
        <p>2. Enable JIT for AARCH64.</p>
        <p>3. AARCH64 tune low-level libraries (ChaCha encryption, XXH3 hash, etc.).</p>
    </section>

    <section class="slide">
        <h2>Conclusion</h2>

        <p>Most problems with ARM optimizations are different cost-model in comparison with X86 (virtual functions, atomics).</p>
        <p>Some things work great on X86, will not work on ARM or will be slow.</p>
        <p>Low-level libraries need to be optimized.</p>
    </section>

    <section class="slide">
        <h2>Questions?</h2>
    </section>

    <div class="progress"></div>
    <script src="shower/shower.min.js"></script>

    <!--Video plugin-->
    <link rel="stylesheet" href="shower/shower-video.css">
    <script src="shower/shower-video.js"></script>
    <!--/Video plugin-->
</body>
</html>
